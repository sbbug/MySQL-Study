## Elasticsearch的读写流程
    自己简单看法：
    任何存储结构都分为读和写两个流程，对于读，所有的存储结构都需要考虑如何更快的读出准确的数据。对于写，任何存储结构都需要考虑如何安全的将数据写入且不丢失。
    ES在设计时也会考虑这两个方面，对于读，为了实现较快的搜索，除了使用倒排索引外，还使用了分片机制，即将数据分摊到不同的主节点，降低单点的压力，通过分片算法减少查询的数据范围。
    对于写，ES需要保证数据可以较快写入存储结构，同时需要保证写入的数据不丢失。比如ES使用translog的同步写保证了写入日志实时落盘，类似MySQL的redo日志，当服务crash后，可以加载translog日志进行重做。
    同时在真正进行写入时，ES并不是把数据直接落盘，而是先写入到内存buffer，由另外的线程进行定时刷新并做落盘操作，极大提高了写入的性能，这个类似MySQL中的change buffer，写数据写入buffer，由后台线程进行定时刷新落盘，唯一不同的是ES读时候直接从磁盘的segment读取数据，
    而MySQL读时会从buffer pool和change buffer两个里面读取最新数据，对change buffer读取的数据进行merge操作，这也是ES读取作为“近实时”的原因。
    当然引入buffer缺点是如果服务crash，可能会出现数据丢失问题，这个重启后可以通过translog恢复。


### 读流程

    ElasticSearch查询分为两个阶段，先是查询，然后取回，即两阶段查询,query-then-fetch。
    
![查询流程](../img/es-query-phase.png)    
    
#### 查询阶段

    1、客户端发送查询请求给某个节点，收到请求的节点作为协调者节点coordinator，协调节点在本地创建一个优先级队列。
    2、然后协调者节点把请求分发给其它分片的主节点或副本节点，收到分发请求的节点会在本地创建优先级队列，并执行查询请求，把结果放到优先级队列中。
    3、每个分片返回各自文档ID集合和对应的排序值给协调节点，协调节点收到后再做一次全局排序，然后放到自己的优先级队列中。

#### 取回阶段

    1、协调者节点辨别哪些文档需要返回，然后向分片节点发送多个GET请求。
    2、每个分片节点加载文档详细内容，然后把内容返回给协调者节点。
    3、一旦所有文档被取回了，协调者将结果返回给客户端。
    
    ElasticSearch分页查询时，会有深度分页的问题，比如查询10000,100,需要创建一个100100大小的优先级队列。也就是说分页是在协调者节点上进行的。
    所以经常出现CPU和内存被打满的问题。

### 写入流程
    
    


## 参考

[ES写入流程-从单分片单副本到多分片多副本](https://longxiaofei.github.io/post/elasticsearch%E7%9A%84%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B/)
